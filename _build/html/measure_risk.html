

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Measuring Risk &mdash; SDC Practice Guide  documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Anonymization Methods" href="anon_methods.html" />
    <link rel="prev" title="Release Types" href="release_types.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> SDC Practice Guide
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary_acr.html">Glossary and list of acronyms</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDC_intro.html">Statistical Disclosure Control (SDC): An Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_types.html">Release Types</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Measuring Risk</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#types-of-disclosure">Types of disclosure</a></li>
<li class="toctree-l2"><a class="reference internal" href="#classification-of-variables">Classification of variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="#disclosure-scenarios">Disclosure scenarios</a></li>
<li class="toctree-l2"><a class="reference internal" href="#levels-of-risk">Levels of risk</a></li>
<li class="toctree-l2"><a class="reference internal" href="#individual-risk">Individual risk</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#categorical-key-variables-and-frequency-counts">Categorical key variables and frequency counts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#anonymity"><span class="math notranslate nohighlight">\(k\)</span>-anonymity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#diversity"><span class="math notranslate nohighlight">\(l\)</span>-diversity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#special-uniques-detection-algorithm-suda">Special Uniques Detection Algorithm (SUDA)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sample-unique-vs-special-unique">Sample unique vs. special unique</a></li>
<li class="toctree-l3"><a class="reference internal" href="#calculating-suda-scores">Calculating SUDA scores</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#risk-measures-for-continuous-variables">Risk measures for continuous variables</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#record-linkage">Record linkage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#interval-measure">Interval measure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#outlier-detection">Outlier detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#global-risk">Global risk</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mean-of-individual-risk-measures">Mean of individual risk measures</a></li>
<li class="toctree-l3"><a class="reference internal" href="#count-of-individuals-with-risks-larger-than-a-certain-threshold">Count of individuals with risks larger than a certain threshold</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#household-risk">Household risk</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="anon_methods.html">Anonymization Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="utility.html">Measuring Utility and Information Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdcMicro.html">SDC with <em>sdcMicro</em> in <em>R</em>: Setting Up Your Data and more</a></li>
<li class="toctree-l1"><a class="reference internal" href="process.html">The SDC Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendices.html">Appendices</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgements.html">Acknowledgements</a></li>
</ul>
<p class="caption"><span class="caption-text">Case studies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="case_studies.html">Case Studies (Illustrating the SDC Process)</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SDC Practice Guide</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Measuring Risk</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/measure_risk.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="measuring-risk">
<h1>Measuring Risk<a class="headerlink" href="#measuring-risk" title="Permalink to this headline">¶</a></h1>
<div class="section" id="types-of-disclosure">
<h2>Types of disclosure<a class="headerlink" href="#types-of-disclosure" title="Permalink to this headline">¶</a></h2>
<p>Measuring disclosure risk is an important part of the SDC process: risk
measures are used to judge whether a data file is safe enough for
release. Before measuring disclosure risk, we have to define what type
of disclosure is relevant for the data at hand. The literature commonly
defines three types of disclosure; we take these directly from <a class="reference internal" href="#lamb93">Lamb93</a>
(see also <a class="reference internal" href="#hdfg12">HDFG12</a>).</p>
<ul class="simple">
<li><strong>Identity disclosure</strong>, which occurs if the intruder associates a
known individual with a released data record. For example, the
intruder links a released data record with external information, or
identifies a respondent with extreme data values. In this case, an
intruder can exploit a small subset of variables to make the linkage,
and once the linkage is successful, the intruder has access to all
other information in the released data related to the specific
respondent.</li>
<li><strong>Attribute disclosure</strong>, which occurs if the intruder is able to
determine some new characteristics of an individual based on the
information available in the released data. Attribute disclosure
occurs if a respondent is correctly re-identified and the dataset
contains variables containing information that was previously unknown
to the intruder. Attribute disclosure can also occur without identity
disclosure. For example, if a hospital publishes data showing that
all female patients aged 56 to 60 have cancer, an intruder then knows
the medical condition of any female patient aged 56 to 60 in the
dataset without having to identify the specific individual.</li>
<li><strong>Inferential disclosure</strong>, which occurs if the intruder is able to
determine the value of some characteristic of an individual more
accurately with the released data than would otherwise have been
possible. For example, with a highly predictive regression model, an
intruder may be able to infer a respondent’s sensitive income
information using attributes recorded in the data, leading to
inferential disclosure.</li>
</ul>
<p>SDC methods for microdata are intended to prevent identity and attribute
disclosure. Inferential disclosure is generally not addressed in SDC in
the microdata setting, since microdata is distributed precisely so that
researchers can make statistical inference and understand relationships
between variables. In that sense, inference cannot be likened to
disclosure. Also, inferences are designed to predict aggregate, not
individual, behavior, and are therefore usually poor predictors of
individual data values.</p>
</div>
<div class="section" id="classification-of-variables">
<h2>Classification of variables<a class="headerlink" href="#classification-of-variables" title="Permalink to this headline">¶</a></h2>
<p>For the purpose of the SDC process, we use the classifications of
variables described in the following paragraphs (see <a class="reference internal" href="#fig24"><span class="std std-numref">Fig. 2</span></a>
for an overview). The initial classification of variables into identifying and
non-identifying variables depends on the way the variables can be used
by intruders for re-identification (<a class="reference internal" href="#hdfg12">HDFG12</a>, <a class="reference internal" href="#temk14">TeMK14</a>):</p>
<ul class="simple">
<li><strong>Identifying variables:</strong> these contain information that can lead to
the identification of respondents and can be further categorized as:<ul>
<li><strong>Direct identifiers</strong> reveal directly and unambiguously the
identity of the respondent. Examples are names, passport numbers,
social identity numbers and addresses. Direct identifiers should
be removed from the dataset prior to release. Removal of direct
identifiers is a straightforward process and always the first step
in producing a safe microdata set for release. Removal of direct
identifiers, however, is often not sufficient.</li>
<li><strong>Quasi-identifiers</strong> (<strong>or key variables</strong>) contain information
that, when combined with other quasi-identifiers in the dataset,
can lead to re-identification of respondents. This is especially
the case when they can be used to match the information with other
external information or data. Examples of quasi-identifiers are
race, birth date, sex and ZIP/postal codes, which might be easily
combined or linked to publically available external information
and make identification possible. The combinations of values of
several quasi-identifiers are called keys (see also the section <a class="reference internal" href="#levels-of-risk">Levels of Risk</a>).
The values of quasi-identifiers themselves often do not lead to
identification (e.g., male/female), but a combination of several
values of quasi-identifier can render a record unique (e.g. male,
14 years, married) and hence identifiable. It is not generally
advisable to simply remove quasi-identifiers from the data to
solve the problem. In many cases, they will be important variables
for any sensible analysis. In practice, any variable in the
dataset could potentially be used as a quasi-identifier. SDC
addresses this by identifying variables as quasi-identifiers and
anonymizing them while still maintaining the information in the
dataset for release.</li>
</ul>
</li>
<li><strong>Non-identifying</strong> variables are variables that cannot be used for
re-identification of respondents. This could be because these
variables are not contained in any other data files or other external
sources and are not observable to an intruder. Non-identifying
variables are nevertheless important in the SDC process, since they
may contain confidential/sensitive information, which may prove
damaging should disclosure occur as a result of identity disclosure
based on identifying variables.</li>
</ul>
<p>These classifications of variables depend partially on the
availability of external datasets that might contain information
that, when combined with the current data, could lead to disclosure.
The identification and classification of variables as
quasi-identifiers depends, amongst others, on the availability of
information in external datasets. An important step in the SDC
process is to define a list of possible disclosure scenarios based on
how the quasi-identifiers might be combined with each other and
information in external datasets and then treating the data to
prevent disclosure. We discuss disclosure scenarios in more detail in
the section <a class="reference internal" href="#disclosure-scenarios">Disclosure scenarios</a>.</p>
<p>For the SDC process, it is also useful to further classify the
quasi-identifiers into <strong>categorical</strong>, <strong>continuous</strong> and
<strong>semi-continuous</strong> variables. This classification is important for
determining the appropriate SDC methods for that variable, as well as
the validity of risk measures.</p>
<ul class="simple">
<li><strong>Categorical</strong> variables take values over a finite set, and any
arithmetic operations using them are generally not meaningful or not
allowed. Examples of categorical variables are gender, region and
education level.</li>
<li><strong>Continuous</strong> variables can take on an infinite number of values in
a given set. Examples are income, body height and size of land plot.
Continuous variables can be transformed into categorical variables by
constructing intervals (such as income bands). <a class="footnote-reference" href="#foot21" id="id1">[1]</a></li>
<li><strong>Semi-continuous</strong> variables are continuous variables that take on
values that are limited to a finite set. An example is age measured
in years, which could take on values in the set {0, 1, …, 100}. The
finite nature of the values for these variables means that they can
be treated as categorical variables for the purpose of
SDC. <a class="footnote-reference" href="#foot22" id="id2">[2]</a></li>
</ul>
<p>Apart from these classifications of variables, the SDC process further
classifies variables according to their sensitivity or confidentiality.
Both quasi-identifiers and non-identifying variables can be classified
as <strong>sensitive</strong> (or confidential) or <strong>non-sensitive</strong> (or
non-confidential). This distinction is not important for direct
identifiers, since direct identifiers are removed from the released
data.</p>
<ul class="simple">
<li><strong>Sensitive</strong> variables contain confidential information that should
not be disclosed without suitable treatment using SDC methods to
reduce disclosure risk. Examples are income, religion, political
affiliation and variables concerning health. Whether a variable is
sensitive depends on the context and country: a certain variable can
be considered sensitive in one country and non-sensitive in another.</li>
<li><strong>Non-sensitive</strong> variables contain non-confidential information on
the respondent, such as place of residence or rural/urban residence.
The classification of a variable as non-sensitive, however, does not
mean that it does not need to be considered in the SDC process.
Non-sensitive variables may still serve as quasi-identifiers when
combined with other variables or other external data.</li>
</ul>
<div class="figure align-center" id="id9">
<span id="fig24"></span><img alt="_images/image24.png" src="_images/image24.png" />
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Classification of variables</span></p>
</div>
</div>
<div class="section" id="disclosure-scenarios">
<h2>Disclosure scenarios<a class="headerlink" href="#disclosure-scenarios" title="Permalink to this headline">¶</a></h2>
<p>Evaluation of disclosure risk is carried out with reference to the
available data sources in the environment where the dataset is to be
released. In this setting, disclosure risk is the possibility of
correctly re-identifying an individual in the released microdata file by
matching their data to an external file based on a set of
quasi-identifiers. The risk assessment is done by identifying so-called
disclosure or intrusion scenarios. A disclosure scenario describes the
information potentially available to the intruder (e.g., census data,
electoral rolls, population registers or data collected by private
firms) to identify respondents and the ways such information can be
combined with the microdata set to be released and used for
re-identification of records in the dataset. Typically, these external
datasets include direct identifiers. In that case, the re-identification
of records in the released dataset leads to identity and, possibly,
attribute disclosure. The main outcome of the evaluation of disclosure
scenarios is the identification of a set of quasi-identifiers (i.e., key
variables) that need to be treated during the SDC process (see <a class="reference internal" href="#elmp10">ELMP10</a>).</p>
<p>An example of a disclosure scenario could be the spontaneous recognition
of a respondent by a researcher. For instance, while going through the
data, the researcher recognizes a person with an unusual combination of
the variables age and marital status. Of course, this can only happen if
the person is well-known or is known to the researcher. Another example
of a disclosure scenario for a publicly available file would be if
variables in the data could be linked to a publically available
electoral register. An intruder might try matching the entire dataset
with individuals in the register. However, this might be difficult and
take specialized expertise, or software, and other conditions have to be
fulfilled. Examples are that the point in time the datasets were
collected should approximately match and the content of the variables
should be (nearly) identical. If these conditions are not fulfilled,
exact matching is much less likely.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Not all external data is
necessarily in the public domain. Also privately owned datasets or
datasets which are not released should be taken into consideration for
determining the suitable disclosure scenario.</p>
</div>
<div class="admonition-info-box-disclosure-scenarios-and-different-release-types admonition">
<p class="first admonition-title">Info-box - Disclosure scenarios and different release types</p>
<p class="last">A dataset can have more than one disclosure scenario. Disclosure scenarios
also differ depending on the data access type that the data will be released
under; for example, Public Use Files (PUF) or Scientific Use Files (SUF, also
known as licensed) or in a data enclave. The required level of protection,
the potential avenues of disclosure as well as the availability of other external
data sources differ according to the access type under which the data will be
released. For example, the user of a Scientific Use File (SUF) might be
contractually restricted by an agreement as to what they are allowed to do
with the data, whereas a Public Use File (PUF) might be freely available on
the internet under a much looser set of conditions. PUFs will in general require
more protection than SUFs and SUFs will require more protection than those files
only released in an data enclave. Disclosure scenarios should be developed with
all of this in mind.</p>
</div>
<p>The evaluation of disclosure risk is based on the quasi-identifiers,
which are identified in the analysis of disclosure risk scenarios. The
disclosure risk directly depends on the inclusion or exclusion of
variables in the set of quasi-identifiers chosen. This step in the SDC
process (making the choice of quasi-identifiers) should therefore be
approached with great thought and care. We will see later, as we discuss
the steps in the SDC process in more detail, that the first step for any
agency is to undertake an exercise in which an inventory is compiled of
all datasets available in the country. Both datasets released by the
national statistical office and from other sources are considered and
their availability to intruders as well as the variables included in
these datasets is analyzed. It is this information that will serve as a
key metric when deciding which variables to choose as potential
identifiers, as well as dictate the level of SDC and methods needed.</p>
</div>
<div class="section" id="levels-of-risk">
<h2>Levels of risk<a class="headerlink" href="#levels-of-risk" title="Permalink to this headline">¶</a></h2>
<p>With microdata from surveys and censuses, we often have to be concerned
about disclosure at the individual or unit level, i.e., identifying
individual respondents. Individual respondents are generally natural
persons, but can also be units, such as companies, schools, health
facilities, etc. Microdata files often have a hierarchical structure
where individual units belong to groups, e.g., people belong to
households. The most common hierarchical structure in microdata is the
household structure in household survey data. Therefore, in this guide,
we sometimes call disclosure risk for data with a hierarchical structure
“household risk”. The concepts, however, apply equally to establishment
data and other data with hierarchical structures, such as school data
with pupils and teachers or company data with employees.</p>
<p>We will see that this hierarchical structure is important to take into
consideration when measuring disclosure risk. For hierarchical data,
information collected at the higher hierarchical level (e.g., household
level) would be the same for all individuals in the group belonging to
that higher hierarchical level (e.g., household). <a class="footnote-reference" href="#foot23" id="id3">[3]</a>
Some typical examples of variables that would have the same values for
all members of the same higher hierarchical unit are, in the case of
households, those relating to housing and household income. These
variables differ from survey to survey and from country to
country. <a class="footnote-reference" href="#foot24" id="id4">[4]</a> This hierarchical structure creates a
further level of disclosure risk for two reasons:</p>
<blockquote>
<div><ol class="arabic simple">
<li>if one individual in the household is re-identified, the household structure allows for
re-identification of the other household members in the same household,</li>
<li>values of variables for other household members that are common for
all household members can be used for re-identification of another
individual of the same household. This is discussed in more detail in
the Section <a class="reference internal" href="#household-risk">Household Risk</a>.</li>
</ol>
</div></blockquote>
<p>Next, we first discuss risk measures used to evaluate
disclosure risk in the absence of a hierarchical structure. This
includes risk measures that seek to aggregate the individual risk for
all individuals in the microdata file; the objective is to quantify a
global disclosure risk measure for the file. We then discuss how risk
measures change when taking the hierarchical structure of the data into
account.</p>
<p>We will also discuss how risk measures differ for categorical and
continuous key variables. For categorical variables, we will use the
concept of uniqueness of combinations of values of quasi-identifiers
(so-called “keys”) used to identify individuals at risk. The concept of
uniqueness, however, is not useful for continuous variables, since it is
likely that all or many individuals will have unique values for that
variable, by definition of a continuous variable. Risk measures for
categorical variables are generally a priori measures, i.e., they can be
evaluated before applying anonymization methods since they are based on
the principle of uniqueness. Risk measures for continuous variables are
a posteriori measures; they are based on comparing the microdata before
and after anonymization and are, for example, based on the proximity of
observations between the original and the treated (anonymized) datasets.</p>
<p>Files that are limited to only categorical or only continuous key
variables are easiest for risk measurement. We will see in later
sections that, in cases where both types of variables are present,
recoding of continuous variables into categories is one approach to use
to simplify the SDC process, but we will also see that from a utility
perspective this may not be desirable. An example might be the use of
income quintiles instead of the actual income variables. We will see
that measuring the risk of disclosure based on the categorical and
continuous variables separately is generally not a valid approach.</p>
<p>The risk measures discussed in the next section are based on several
assumptions. In general, these measures rely on quite restrictive
assumptions and will often lead to conservative risk estimates. These
conservative risk measures may overstate the risk as they assume a
worst-case scenario. Two assumptions should, however, be fulfilled for
the risk measures to be valid and meaningful; the microdata should be a
sample of a larger population (no census) and the sampling weights
should be available. The Section
<a class="reference external" href="anon_methods.html#Specialcase:censusdata">Special case: census data</a>
briefly discusses how to deal with census data.</p>
</div>
<div class="section" id="individual-risk">
<h2>Individual risk<a class="headerlink" href="#individual-risk" title="Permalink to this headline">¶</a></h2>
<div class="section" id="categorical-key-variables-and-frequency-counts">
<h3>Categorical key variables and frequency counts<a class="headerlink" href="#categorical-key-variables-and-frequency-counts" title="Permalink to this headline">¶</a></h3>
<p>The main focus of risk measurement for categorical quasi-identifiers is
on identity disclosure. Measuring disclosure risk is based on the
evaluation of the probability of correct re-identification of
individuals in the released data. We use measures based on the actual
microdata to be released. In general, the rarer a combination of values
of the quasi-identifiers (i.e., key) of an observation in the sample,
the higher the risk of identity disclosure. An intruder that tries to
match an individual who has a relatively rare key within the sample data
with an external dataset in which the same key exists will have a higher
probability of finding a correct match than when a larger number of
individuals share the same key. This can be illustrated with the
following example that is illustrated in <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a>.</p>
<p><a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a> shows values for 10 respondents for the quasi-identifiers
“residence”, “gender”, “education level” and “labor status”. In the
data, we find seven unique combinations of values of quasi-identifiers
(i.e., patterns or keys) of the four quasi-identifiers. Examples of keys
are {‘urban’, ‘female’, ‘secondary incomplete’, ‘employed’} and
{‘urban’, ‘female’, ‘primary incomplete’, ‘non-LF’}. Let <span class="math notranslate nohighlight">\(f_{k}\)</span>
be the sample frequency of the <span class="math notranslate nohighlight">\(k\)</span><sup>th</sup> key, i.e., the number of
individuals in the sample with values of the quasi-identifiers that
coincide with the <span class="math notranslate nohighlight">\(k\)</span><sup>th</sup> key. This would be 2 for the key
{urban, female, secondary incomplete, employed}, since this key is
shared by individuals 1 and 2 and 1 for the key {‘urban’, ‘female’,
‘primary incomplete’, ‘non-LF’}, which is unique to individual 3. By
definition, <span class="math notranslate nohighlight">\(f_{k}\)</span> is the same for each record sharing a
particular key.</p>
<p>The fewer the individuals with whom an individual shares his or her
combination of quasi-identifiers, the more likely the individual is to
be correctly matched in another dataset that contains these
quasi-identifiers. Even when direct identifiers are removed from the
dataset, that individual has a higher disclosure risk than others,
assuming that their sample weights are the same. <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a> reports the
sample frequencies <span class="math notranslate nohighlight">\(f_{k}\)</span> of the keys for all individuals.
Individuals with the same keys have the same sample frequency. If
<span class="math notranslate nohighlight">\(f_{k} = 1\)</span>, this individual has a unique combination of values of
quasi-identifiers and is called “sample unique”. The dataset in <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a>
contains four sample uniques. Risk measures are based on this sample
frequency.</p>
<span id="tab41"></span><table border="1" class="colwidths-auto docutils align-center" id="id10">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Example dataset showing sample frequencies,
                     population frequencies and individual disclosure risk</span><a class="headerlink" href="#id10" title="Permalink to this table">¶</a></caption>
<thead valign="bottom">
<tr class="row-odd"><th class="head">No</th>
<th class="head">Residence</th>
<th class="head">Gender</th>
<th class="head">Education level</th>
<th class="head">Labor status</th>
<th class="head">Weight</th>
<th class="head"><span class="math notranslate nohighlight">\(f_{k}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(F_{k}\)</span></th>
<th class="head">risk</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>180</td>
<td>2</td>
<td>360</td>
<td>0.0054</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>180</td>
<td>2</td>
<td>360</td>
<td>0.0054</td>
</tr>
<tr class="row-even"><td>3</td>
<td>Urban</td>
<td>Female</td>
<td>Primary incomplete</td>
<td>Non-LF</td>
<td>215</td>
<td>1</td>
<td>215</td>
<td>0.0251</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>76</td>
<td>2</td>
<td>152</td>
<td>0.0126</td>
</tr>
<tr class="row-even"><td>5</td>
<td>Rural</td>
<td>Female</td>
<td>Secondary complete</td>
<td>Unemployed</td>
<td>186</td>
<td>1</td>
<td>186</td>
<td>0.0282</td>
</tr>
<tr class="row-odd"><td>6</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>76</td>
<td>2</td>
<td>152</td>
<td>0.0126</td>
</tr>
<tr class="row-even"><td>7</td>
<td>Urban</td>
<td>Female</td>
<td>Primary complete</td>
<td>Non-LF</td>
<td>180</td>
<td>1</td>
<td>180</td>
<td>0.0290</td>
</tr>
<tr class="row-odd"><td>8</td>
<td>Urban</td>
<td>Male</td>
<td>Post-secondary</td>
<td>Unemployed</td>
<td>215</td>
<td>1</td>
<td>215</td>
<td>0.0251</td>
</tr>
<tr class="row-even"><td>9</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>186</td>
<td>2</td>
<td>262</td>
<td>0.0074</td>
</tr>
<tr class="row-odd"><td>10</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>76</td>
<td>2</td>
<td>262</td>
<td>0.0074</td>
</tr>
</tbody>
</table>
<p>For sample data, it is more interesting to look at <span class="math notranslate nohighlight">\(F_{k}\)</span>, the
population frequency of a combination of quasi-identifiers (key)
<span class="math notranslate nohighlight">\(k\)</span>, which is the number of individuals in the population with the
key that corresponds to key <span class="math notranslate nohighlight">\(k\)</span>. The population frequency
is unknown if the microdata is a sample and not a census. Under certain
assumptions, the expected value of the population frequencies can be
computed using the sample design weight <span class="math notranslate nohighlight">\(w_{i}\)</span> (in a simple
sample, this is the inverse of the inclusion probability) for each
individual <span class="math notranslate nohighlight">\(i\)</span></p>
<div class="math notranslate nohighlight">
\[F_{k} = \sum_{i|key\ of\ individual\ i\ corresponds\ to\ key\ k}^{}w_{i}\]</div>
<p><span class="math notranslate nohighlight">\(F_{k}\)</span> is the sum of the sample weights of all records with the
same key <span class="math notranslate nohighlight">\(k\)</span>. Hence, like <span class="math notranslate nohighlight">\(f_{k}\)</span>, <span class="math notranslate nohighlight">\(F_{k}\)</span> is the same for
each record with key <span class="math notranslate nohighlight">\(k\)</span>. The risk of correct re-identification is the
probability that the key is matched to the correct individual in the
population. Since every individual in the sample with key <span class="math notranslate nohighlight">\(k\)</span>
corresponds to <span class="math notranslate nohighlight">\(F_{k}\)</span> individuals in the population, the
probability of correct re-identification is <span class="math notranslate nohighlight">\(1/F_{k}\)</span>. This is
the probability of re-identification in the worst-case scenario and can
be interpreted as disclosure risk. Individuals with the same key have
the same frequencies, i.e., the frequency of the key.</p>
<p>If <span class="math notranslate nohighlight">\(F_{k} = 1\)</span>, the key <span class="math notranslate nohighlight">\(k\)</span> is both a sample and a
population unique and the disclosure risk would be 1. Population uniques
are an important factor to consider when evaluating risk, and deserve
special attention. <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a> also shows <span class="math notranslate nohighlight">\(F_{k}\)</span> for the example
dataset. This is further discussed in the case studies the Section
<a class="reference external" href="case_studies.html">Case Studies</a>.</p>
<p>In practice, this approach leads to conservative risk estimates, as it
does not adequately take the sampling methods into account. In this
case, the estimates of re-identification risk may be estimated too high.
If this overestimated risk is used, the data may be overprotected (i.e.,
information loss will be higher than was necessary) when applying SDC
measures. Instead, a Bayesian approach to risk measurement is
recommended, where the posterior distribution of <span class="math notranslate nohighlight">\(F_{k}\)</span> is used
(see e.g., <a class="reference internal" href="#hdfg12">HDFG12</a>) to estimate an individual risk
measure <span class="math notranslate nohighlight">\(r_{k}\)</span> for each key <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>ADD: more info on the exact computation of r_k</p>
<p>The risk measure <span class="math notranslate nohighlight">\(r_{k}\)</span> is, as <span class="math notranslate nohighlight">\(f_{k}\)</span> and <span class="math notranslate nohighlight">\(F_{k}\)</span>,
the same for all individuals sharing the same pattern of values of key
variables and is referred to as individual risk. The values
<span class="math notranslate nohighlight">\(r_{k}\)</span> can also be interpreted as the probability of disclosure
for the individuals or as the probability for a successful match with
individuals chosen at random from an external data file with the same
values of the key variables. This risk measure is based on certain
assumptions <a class="footnote-reference" href="#foot26" id="id5">[5]</a>, which are strict and may lead to a
relatively conservative risk measure. The risk measures are also presented in <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a>.</p>
<p>The main factors influencing the individual risk are the sample
frequencies <span class="math notranslate nohighlight">\(f_{k}\)</span> and the sampling design weights <span class="math notranslate nohighlight">\(w_{i}\)</span>.
If an individual is at relatively high risk of disclosure, in our
example this would be individuals 3, 5, 7 and 8 in <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a>,
the probability that a potential intruder correctly matches these
individuals with an external data file is high <strong>relative to the other
individuals in the released data.</strong> In our example, the reason for the
high risk is the fact that these individuals are sample uniques
<span class="math notranslate nohighlight">\((f_{k} = 1)\)</span>. This risk is the worst-case scenario risk and does
not imply that the person will be re-identified with certainty with this
probability. For instance, if an individual included in the microdata is
not included in the external data file, the probability for a correct
match is zero. Nevertheless, the risk measure computed based on the
frequencies will be positive.</p>
</div>
<div class="section" id="anonymity">
<h3><span class="math notranslate nohighlight">\(k\)</span>-anonymity<a class="headerlink" href="#anonymity" title="Permalink to this headline">¶</a></h3>
<p>The risk measure <span class="math notranslate nohighlight">\(k\)</span>-anonymity is based on the principle that, in a safe
dataset, the number of individuals sharing the same combination of
values (keys) of categorical quasi-identifiers should be higher than a
specified threshold <span class="math notranslate nohighlight">\(k\)</span>. <span class="math notranslate nohighlight">\(k\)</span>-anonymity is a risk
measure based on the microdata to be released, since it only takes the
sample into account. An individual violates <span class="math notranslate nohighlight">\(k\)</span>-anonymity if the
sample frequency count <span class="math notranslate nohighlight">\(f_{k}\)</span> for the key <span class="math notranslate nohighlight">\(k\)</span> is smaller
than the specified threshold <span class="math notranslate nohighlight">\(k\)</span>. For example, if an
individual has the same combination of quasi-identifiers as two other
individuals in the sample, these individuals satisfy 3-anonymity but
violate 4-anonymity. In the dataset in <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a>, six individuals
satisfy 2-anonymity and four violate 2-anonymity. The individuals that
violate 2-anonymity are sample uniques. The risk measure is the number
of observations that violates k-anonymity for a certain value of <em>k</em>,
which is</p>
<div class="math notranslate nohighlight">
\[\sum_{i}^{}{I(f_{k} &lt; k)},\]</div>
<p>where <span class="math notranslate nohighlight">\(I\)</span> is the indicator function and <span class="math notranslate nohighlight">\(i\)</span> refers to the
<span class="math notranslate nohighlight">\(i\)</span><sup>th</sup> record. This is simply a count of the number of
individuals with a sample frequency of their key lower than <span class="math notranslate nohighlight">\(k\)</span>.
The count is higher for larger <span class="math notranslate nohighlight">\(k\)</span>, since if a record satisfies
<span class="math notranslate nohighlight">\(k\)</span>-anonymity, it also satisfies <span class="math notranslate nohighlight">\((k + 1)\)</span>-anonymity. The
risk measure <span class="math notranslate nohighlight">\(k\)</span>-anonymity does not consider the sample weights,
but it is important to consider the sample weights when determining the
required level of <span class="math notranslate nohighlight">\(k\)</span>-anonymity. If the sample weights are large,
one individual in the dataset represents more individuals in the target
population, the probability of a correct match is smaller, and hence the
required threshold can be lower. Large sample weights go together with
smaller datasets. In a smaller dataset, the probability to find another
record with the same key is smaller than in a larger dataset. This
probability is related to the number of records in the population with a
particular key through the sample weights.</p>
<p>Assuming that the example dataset in <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a> represents the full
sample, we find that four observations violate 2-anonymity (<span class="math notranslate nohighlight">\(f_{k} &lt; 2\)</span>)
and all 10 observations violate 3-anonymity (<span class="math notranslate nohighlight">\(f_{k} &lt; 3\)</span>). The relative
number of 2-anonymity and 3-anonymity violators are resp. 40% and 100%.
For other levels of <span class="math notranslate nohighlight">\(k\)</span>-anonymity, it is possible to compute the
number of violating individuals by using the sample frequency counts.
<span class="math notranslate nohighlight">\(k\)</span> can be replaced with any required threshold. The choice of the
required threshold that all individuals in the microdata file should
satisfy depends on many factors and is discussed further in the Section
<a class="reference external" href="anon_methods.html#Localsuppression">Local suppression</a>
on local suppression. In many institutions, typically required
thresholds for <span class="math notranslate nohighlight">\(k\)</span>-anonymity are 3 and 5.</p>
<p>It is important to note that missing values are treated as if they were any other value.
Two individuals with keys {‘Male’, missing, ‘Employed’} and {‘Male’,
‘Secondary complete’, ‘Employed’} share the same key, and similarly,
{‘Male’, missing, ‘Employed’} and {‘Male’, ‘Secondary incomplete’,
‘Employed’} also share the same key. Therefore, the missing value in the
first key is first interpreted as ‘Secondary complete’, and then as
‘Secondary incomplete’. This is illustrated in <a class="reference internal" href="#tab42"><span class="std std-numref">Table 2</span></a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The sample frequency of the third record is 3, since it is regarded to share
its key both with the first and second record.</p>
</div>
<p>This principle is used when applying local suppression to achieve a certain level of
<span class="math notranslate nohighlight">\(k\)</span>-anonymity (see the Section <a class="reference external" href="anon_methods.html#Localsuppression">Local suppression</a>)
and is based on the fact that the value NA could replace any value.</p>
<p>ADD: parameter alpha and treating missing values</p>
<span id="tab42"></span><table border="1" class="colwidths-auto docutils align-center" id="id11">
<caption><span class="caption-number">Table 2 </span><span class="caption-text">Example dataset to illustrate the effect of missing values on k-anonymity</span><a class="headerlink" href="#id11" title="Permalink to this table">¶</a></caption>
<thead valign="bottom">
<tr class="row-odd"><th class="head">No</th>
<th class="head">Gender</th>
<th class="head">Education level</th>
<th class="head">Labor status</th>
<th class="head"><span class="math notranslate nohighlight">\(f_{k}\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>2</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>Male</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>2</td>
</tr>
<tr class="row-even"><td>3</td>
<td>Male</td>
<td>NA</td>
<td>Employed</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>If a dataset satisfies <span class="math notranslate nohighlight">\(k\)</span>-anonymity, an intruder will always find
at least <span class="math notranslate nohighlight">\(k\)</span> individuals with the same combination of
quasi-identifiers. <span class="math notranslate nohighlight">\(k\)</span>-anonymity is often a necessary requirement
for anonymization for a dataset before release, but is not necessarily a
sufficient requirement. The <span class="math notranslate nohighlight">\(k\)</span>-anonymity measure is only based on
frequency counts and does not take (differences in) sample weights into
account. Often <span class="math notranslate nohighlight">\(k\)</span>-anonymity is achieved by first applying
recoding and subsequently applying local suppression, and in some cases
by microaggregation, before using other risk measures and disclosure
methods to further reduce disclosure risk. These methods are discussed
in the Section <a class="reference external" href="anon_methods.html">Anonymization methods</a>.</p>
</div>
<div class="section" id="diversity">
<h3><span class="math notranslate nohighlight">\(l\)</span>-diversity<a class="headerlink" href="#diversity" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(k\)</span>-anonymity has been criticized for not being restrictive
enough. Sensitive information might be disclosed even if the data
satisfies <span class="math notranslate nohighlight">\(k\)</span>-anonymity. This might occur in cases where the data
contains sensitive (non-identifying) categorical variables that have the
same value for all individuals that share the same key. Examples of such
sensitive variables are those containing information on an individual’s
health status. <a class="reference internal" href="#tab43"><span class="std std-numref">Table 3</span></a> illustrates this problem by using the same data
as previously used, but adding a sensitive variable, ”health”. The first
two individuals satisfy 2-anonymity for the key variables “residence”,
“gender”, “education level” and “labor status”. This means that an
intruder will find at least two individuals when matching to the
released microdata set based on those four quasi-identifiers.
Nevertheless, if the intruder knows that someone belongs to the sample
and has the key {‘Urban’, ‘Female’, ‘Secondary incomplete’ and
‘Employed’}, with certainty the health status is disclosed (‘yes’),
because both observations with this key have the same value. This
information is thus disclosed without the necessity to match exactly to
the individual. This is not the case for the individuals with the key
{‘Urban’, ‘Male’, ‘Secondary complete’, ‘Employed’}. Individuals 4 and 6
have different values (‘yes’ and ‘no’) for “health”, and thus the
intruder would not gain information about the health status from this
dataset by matching an individual to one of these individuals.</p>
<span id="tab43"></span><table border="1" class="colwidths-auto docutils align-center" id="id12">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">l-diversity illustration</span><a class="headerlink" href="#id12" title="Permalink to this table">¶</a></caption>
<thead valign="bottom">
<tr class="row-odd"><th class="head">No</th>
<th class="head">Residence</th>
<th class="head">Gender</th>
<th class="head">Education level</th>
<th class="head">Labor status</th>
<th class="head">Health</th>
<th class="head"><span class="math notranslate nohighlight">\(f_{k}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(F_{k}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(l\)</span>-diversity</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>yes</td>
<td>2</td>
<td>360</td>
<td>1</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>yes</td>
<td>2</td>
<td>360</td>
<td>1</td>
</tr>
<tr class="row-even"><td>3</td>
<td>Urban</td>
<td>Female</td>
<td>Primary incomplete</td>
<td>Non-LF</td>
<td>yes</td>
<td>1</td>
<td>215</td>
<td>1</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>yes</td>
<td>2</td>
<td>152</td>
<td>2</td>
</tr>
<tr class="row-even"><td>5</td>
<td>Rural</td>
<td>Female</td>
<td>Secondary complete</td>
<td>Unemployed</td>
<td>yes</td>
<td>1</td>
<td>186</td>
<td>1</td>
</tr>
<tr class="row-odd"><td>6</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>no</td>
<td>2</td>
<td>152</td>
<td>2</td>
</tr>
<tr class="row-even"><td>7</td>
<td>Urban</td>
<td>Female</td>
<td>Primary complete</td>
<td>Non-LF</td>
<td>no</td>
<td>1</td>
<td>180</td>
<td>1</td>
</tr>
<tr class="row-odd"><td>8</td>
<td>Urban</td>
<td>Male</td>
<td>Post-secondary</td>
<td>Unemployed</td>
<td>yes</td>
<td>1</td>
<td>215</td>
<td>1</td>
</tr>
<tr class="row-even"><td>9</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>no</td>
<td>2</td>
<td>262</td>
<td>2</td>
</tr>
<tr class="row-odd"><td>10</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>yes</td>
<td>2</td>
<td>262</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>The concept of (distinct) <span class="math notranslate nohighlight">\(l\)</span>-diversity addresses this shortcoming
of <span class="math notranslate nohighlight">\(k\)</span>-anonymity (see <a class="reference internal" href="#mkgv07">MKGV07</a>). A dataset
satisfies <span class="math notranslate nohighlight">\(l\)</span>-diversity if for every key <span class="math notranslate nohighlight">\(k\)</span> there are at least
<span class="math notranslate nohighlight">\(l\)</span> different values for each of the sensitive variables. In the
example, the first two individuals satisfy only 1-diversity, individuals
4 and 6 satisfy 2-diversity. The required level of <span class="math notranslate nohighlight">\(l\)</span>-diversity
depends on the number of possible values the sensitive variable can
take. If the sensitive variable is a binary variable, the highest level
if <span class="math notranslate nohighlight">\(l\)</span>-diversity that can be achieved is 2. A sample unique will
always only satisfy 1-diversity.</p>
<p>ADD: recursive l-diversity and parameter l_recurs_c in ldiversity()</p>
<p><span class="math notranslate nohighlight">\(l\)</span>-diversity is useful if the data contains categorical sensitive
variables that are not quasi-identifiers themselves. It is not possible
to select quasi-identifiers to calculate the <span class="math notranslate nohighlight">\(l\)</span>-diversity.
<span class="math notranslate nohighlight">\(l\)</span>-diversity has to be calculated for each sensitive variable
separately.</p>
</div>
</div>
<div class="section" id="special-uniques-detection-algorithm-suda">
<h2>Special Uniques Detection Algorithm (SUDA)<a class="headerlink" href="#special-uniques-detection-algorithm-suda" title="Permalink to this headline">¶</a></h2>
<p>The previously discussed risk measures depend on identifying key
variables for which there may be information available from other
sources or other datasets, and which, when combined with the current
data, may lead to re-identification. In practice, however, it might not
always be possible to conduct an inventory of all available datasets and
their variables and thus assess all known external linkages and risks.</p>
<p>To overcome this, an alternative heuristic measure based on special
uniques has been developed to determine the riskiness of a record, which
leads to a SUDA metric or score (see <a class="reference internal" href="#elmf02">ElMF02</a>). These
measures are based on the search for special uniques. To find these
special uniques, algorithms, called SUDA (Special Uniqueness Detection
Algorithm), have been developed. SUDA algorithms are based on the
concept of special uniqueness, which is introduced in the next
subsection. Since this is a heuristic approach, its performance is only
tested in actual datasets, which is done in <a class="reference internal" href="#elmf02">ElMF02</a> for UK
census data. These tests have shown that the performance of the
algorithm leads to good risk estimates for these test datasets.</p>
<div class="section" id="sample-unique-vs-special-unique">
<h3>Sample unique vs. special unique<a class="headerlink" href="#sample-unique-vs-special-unique" title="Permalink to this headline">¶</a></h3>
<p>The previous measures of risk focused on the uniqueness of the key of a
record in the dataset. <a class="reference internal" href="#tab44"><span class="std std-numref">Table 4</span></a> reproduces the data from <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a>. The
sample dataset has 10 records and four pre-determined quasi-identifiers
{“Residence”, “Gender”, “Education level” and “Labor status”}. Given the
four quasi-identifiers, we have seven distinct patterns in those key
variables, or keys (e.g., {‘Urban’, ‘Female’, ‘Secondary incomplete’,
‘Employed’}). The sample frequency counts of the first and second
records equal 2, because the two records share the same pattern (i.e.,
{‘Urban’, ‘Female’, ‘Secondary incomplete’, ‘Employed’}). Record 3 is a
sample unique because it is the only individual in the sample who is a
female living in an urban area who is employed without completing
primary school. Similarly, records 5, 7 and 8 are sample uniques,
because they possess distinct patterns with respect to the four key
variables.</p>
<span id="tab44"></span><table border="1" class="colwidths-auto docutils align-center" id="id13">
<caption><span class="caption-number">Table 4 </span><span class="caption-text">Sample uniques and special uniques</span><a class="headerlink" href="#id13" title="Permalink to this table">¶</a></caption>
<thead valign="bottom">
<tr class="row-odd"><th class="head">No</th>
<th class="head">Residence</th>
<th class="head">Gender</th>
<th class="head">Education level</th>
<th class="head">Labor status</th>
<th class="head">Weight</th>
<th class="head"><span class="math notranslate nohighlight">\(f_{k}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(F_{k}\)</span></th>
<th class="head">risk</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>180</td>
<td>2</td>
<td>360</td>
<td>0.0054</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>180</td>
<td>2</td>
<td>360</td>
<td>0.0054</td>
</tr>
<tr class="row-even"><td>3</td>
<td>Urban</td>
<td>Female</td>
<td>Primary incomplete</td>
<td>Non-LF</td>
<td>215</td>
<td>1</td>
<td>215</td>
<td>0.0251</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>76</td>
<td>2</td>
<td>152</td>
<td>0.0126</td>
</tr>
<tr class="row-even"><td>5</td>
<td>Rural</td>
<td>Female</td>
<td>Secondary complete</td>
<td>Unemployed</td>
<td>186</td>
<td>1</td>
<td>186</td>
<td>0.0282</td>
</tr>
<tr class="row-odd"><td>6</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>76</td>
<td>2</td>
<td>152</td>
<td>0.0126</td>
</tr>
<tr class="row-even"><td>7</td>
<td>Urban</td>
<td>Female</td>
<td>Primary complete</td>
<td>Non-LF</td>
<td>180</td>
<td>1</td>
<td>180</td>
<td>0.0290</td>
</tr>
<tr class="row-odd"><td>8</td>
<td>Urban</td>
<td>Male</td>
<td>Post-secondary</td>
<td>Unemployed</td>
<td>215</td>
<td>1</td>
<td>215</td>
<td>0.0251</td>
</tr>
<tr class="row-even"><td>9</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>186</td>
<td>2</td>
<td>262</td>
<td>0.0074</td>
</tr>
<tr class="row-odd"><td>10</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>76</td>
<td>2</td>
<td>262</td>
<td>0.0074</td>
</tr>
</tbody>
</table>
<p>In addition to the records 3, 5, 7 and 8 in <a class="reference internal" href="#tab44"><span class="std std-numref">Table 4</span></a> being sample
uniques with respect to the key variable set {“Residence”, “Gender”,
“Education level”, “Labor status”}, we can find unique patterns in these
records without even having to consider the complete set of key
variables. For instance, a unique pattern can be found in record 5 when
we look only at the variables “Education level” and “Labor status”
({‘Secondary complete’, ‘Unemployed’}). While the values {‘Secondary
complete’} and {‘Unemployed’} are not unique in the sample, the
combination of them, {‘Secondary complete’, ‘Unemployed’} makes record 5
unique. This variable subset is referred to as the Minimal Sample Unique
(MSU) as any smaller subset of this set of variables is not unique (in
this case {‘Secondary complete’} and {‘Unemployed’}). It is an MSU of
size 2. This holds as well
for three other combinations in record 5, i.e., {‘Female’, ‘Unemployed’}
and {‘Female’, ‘Secondary Complete’}, which are also MSUs of size 2 and
{‘Rural’} of size 1. In total, record 5 has four
MSUs <a class="footnote-reference" href="#foot31" id="id6">[7]</a>. To determine if a set is an MSU of size
<span class="math notranslate nohighlight">\(k\)</span>, we check whether it fulfills the minimal requirement. It
suffices to check whether all subsets of size <span class="math notranslate nohighlight">\(k-1\)</span> of the MSU are
unique. If any of these subsets are also unique in the sample, the set
found may be a sample unique, but violates the minimal requirement and
is hence not an MSU. The unique subset of size <span class="math notranslate nohighlight">\(k-1\)</span> could be a
MSU. In our example, to determine if the MSU {‘Secondary complete’,
‘Unemployed’} is a MSU, we checked as to whether its subsets {‘Secondary
complete’} and {‘Unemployed’} were not unique in the sample. By
definition, only sample uniques can be special uniques.</p>
<p>The SUDA algorithm identifies all the MSUs in the sample, which in turn
are used to assign a SUDA score to each record. This score indicates how
“risky” a record is. The potential risk of the records is determined
based on two observations:</p>
<ul class="simple">
<li>The smaller the size of the MSU within a record (i.e., the fewer
variables are needed to reach uniqueness), the greater the risk of
the record</li>
<li>The larger the number of MSUs possessed by a record, the greater the
risk of the record</li>
</ul>
<p>A record is defined as a special unique if it is a sample unique both on
the complete set of quasi-identifiers (e.g., in the data in <a class="reference internal" href="#tab44"><span class="std std-numref">Table 4</span></a>,
the variables “Residence”, ”Gender”, “Education level” and “Labor
status”) and simultaneously has at least one MSU (<a class="reference internal" href="#elsd98">ElSD98</a>).
Special uniques can be classified according to the number and size of
subsets that are MSUs. Research has shown that special uniques are more
likely to be population uniques than random uniques (<a class="reference internal" href="#elmf02">ElMF02</a>)
and are thus relevant for risk assessment.</p>
</div>
<div class="section" id="calculating-suda-scores">
<h3>Calculating SUDA scores<a class="headerlink" href="#calculating-suda-scores" title="Permalink to this headline">¶</a></h3>
<p>The SUDA algorithm is used to search for MSUs in the data among the
sample uniques to determine which sample uniques are also special
uniques i.e., have subsets that are also unique (see Elliot et al.,
2005). First the SUDA algorithm is used to identify the MSUs for each
sample unique. To simplify the search and because smaller subsets are
more important for disclosure risk, the search is limited to a maximum
subset size. Subsequently, a score is assigned to each individual, which
ranks the individuals according to their level of risk.</p>
<p>For each MSU of size <span class="math notranslate nohighlight">\(k\)</span> contained in a given record, a score is
computed by <span class="math notranslate nohighlight">\(\prod_{i = k}^{M}{(ATT - i)}\)</span>, where <span class="math notranslate nohighlight">\(M\)</span> is the
user-specified maximum size of MSUs <a class="footnote-reference" href="#foot32" id="id7">[8]</a>, and
<span class="math notranslate nohighlight">\(ATT\)</span> is the total number of attributes or variables in the
dataset. By definition, the smaller the size <span class="math notranslate nohighlight">\(k\)</span> of the MSU, the
larger the score for the MSU, which reflects greater risk (see <a class="reference internal" href="#emmg05">EMMG05</a>).
The final SUDA score for each record is computed by adding
the scores for each MSU in the record. In this way, records with more
MSUs are assigned a higher SUDA score, which also reflects the higher
risk. The SUDA score ranks the individuals according to their level of
risk. The higher the SUDA score, the riskier the sample unique.</p>
<p><em>Calculating SUDA scores – a simplified example</em></p>
<p>To illustrate how SUDA scores are calculated, we compute the SUDA scores
for the sample uniques in the data in <a class="reference internal" href="#tab45"><span class="std std-numref">Table 5</span></a>, which replicates the
data from <a class="reference internal" href="#tab45"><span class="std std-numref">Table 5</span></a>. Record 5 contains four MSUs: {Rural} of size 1, and
{‘Secondary Complete’, ‘Unemployed’}, {‘Female’, ‘Unemployed’} and
{Female, Secondary Complete} of size 2. Suppose the maximum size of MSUs
we search for in the data, <span class="math notranslate nohighlight">\(M\)</span>, is set at 3. Knowing that,
<span class="math notranslate nohighlight">\(ATT\)</span>, the number of selected key variables in the dataset,
is 4; the score assigned to {Rural} is computed by
<span class="math notranslate nohighlight">\(\prod_{i = 1}^{3}{(4 - i)} = 3*2*1 = 6\)</span>; and the score assigned
to {Secondary complete, Unemployed}, {Female, Unemployed} and {Female,
Secondary Complete} is
<span class="math notranslate nohighlight">\(\prod_{i = 2}^{3}\left( 4 - i \right) = 2*1 = 2\)</span>. The SUDA score
for the fifth record in <a class="reference internal" href="#tab45"><span class="std std-numref">Table 5</span></a> is then <span class="math notranslate nohighlight">\(6 + 2 + 2 + 2 = 12\)</span>,
which is the sum of these four scores per MSU. The SUDA scores for the
other sample uniques are computed accordingly <a class="footnote-reference" href="#foot33" id="id8">[9]</a>. The
values that are in the MSUs in the sample uniques are shaded in <a class="reference internal" href="#tab45"><span class="std std-numref">Table 5</span></a>.
Records that are not sample uniques (<span class="math notranslate nohighlight">\(f_{k} &gt; 1\)</span>) cannot be
special uniques and are assigned the score 0.</p>
<span id="tab45"></span><table border="1" class="colwidths-auto docutils align-center" id="id14">
<caption><span class="caption-number">Table 5 </span><span class="caption-text">Illustrating the calculation of SUDA and DIS-SUDA scores</span><a class="headerlink" href="#id14" title="Permalink to this table">¶</a></caption>
<thead valign="bottom">
<tr class="row-odd"><th class="head">No</th>
<th class="head">Residence</th>
<th class="head">Gender</th>
<th class="head">Education level</th>
<th class="head">Labor status</th>
<th class="head">Weight</th>
<th class="head"><span class="math notranslate nohighlight">\(f_{k}\)</span></th>
<th class="head">SUDA score</th>
<th class="head">DIS-SUDA</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>180</td>
<td>2</td>
<td>0</td>
<td>0.0000</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Employed</td>
<td>180</td>
<td>2</td>
<td>0</td>
<td>0.0000</td>
</tr>
<tr class="row-even"><td>3</td>
<td>Urban</td>
<td>Female</td>
<td>Primary incomplete</td>
<td>Non-LF</td>
<td>215</td>
<td>1</td>
<td>6</td>
<td>0.0051</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>76</td>
<td>2</td>
<td>0</td>
<td>0.0000</td>
</tr>
<tr class="row-even"><td>5</td>
<td>Rural</td>
<td>Female</td>
<td>Secondary complete</td>
<td>Unemployed</td>
<td>186</td>
<td>1</td>
<td>12</td>
<td>0.0107</td>
</tr>
<tr class="row-odd"><td>6</td>
<td>Urban</td>
<td>Male</td>
<td>Secondary complete</td>
<td>Employed</td>
<td>76</td>
<td>2</td>
<td>0</td>
<td>0.0000</td>
</tr>
<tr class="row-even"><td>7</td>
<td>Urban</td>
<td>Female</td>
<td>Primary complete</td>
<td>Non-LF</td>
<td>180</td>
<td>1</td>
<td>6</td>
<td>0.0051</td>
</tr>
<tr class="row-odd"><td>8</td>
<td>Urban</td>
<td>Male</td>
<td>Post-secondary</td>
<td>Unemployed</td>
<td>215</td>
<td>1</td>
<td>10</td>
<td>0.0088</td>
</tr>
<tr class="row-even"><td>9</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>186</td>
<td>2</td>
<td>0</td>
<td>0.0000</td>
</tr>
<tr class="row-odd"><td>10</td>
<td>Urban</td>
<td>Female</td>
<td>Secondary incomplete</td>
<td>Non-LF</td>
<td>76</td>
<td>2</td>
<td>0</td>
<td>0.0000</td>
</tr>
</tbody>
</table>
<p>ADD: compare with values in code block 4.7</p>
<p>To estimate record-level disclosure risks, SUDA scores can be used in
combination with the Data Intrusion Simulation (DIS) metric (<a class="reference internal" href="#elma03">ElMa03</a>),
a method for assessing disclosure risks for the entire
dataset (i.e., file-level disclosure risks). Roughly speaking, the
DIS-SUDA method distributes the file-level risk measure generated by the
DIS metric between records according to the SUDA scores of each record.
This way, SUDA scores are calibrated against a consistent measure to
produce the DIS-SUDA scores, which provide the record-level disclosure
risk. These scores are used to compute the conditional probability that
a unique match found by an intruder between the sample unique in the
released microdata and an external data source is also a correct match,
and hence a successful disclosure. The DIS-SUDA measure can be computed
in <em>sdcMicro</em>. Since the DIS score is a probability, its values are in
the interval <span class="math notranslate nohighlight">\(\lbrack 0,\ 1\rbrack\)</span>. A full description of the
DIS-SUDA method is provided by <a class="reference internal" href="#elma03">ElMa03</a>.</p>
<p>Note that unlike the risk methods discussed earlier, the DIS-SUDA score
does not fully account for the sampling weights. Risk measures based on
the previous methods (i.e., negative binomial models) will in general
have lower risks for those records with greater sampling weight, given
the same sample frequency count, than those measured using DIS-SUDA.
Therefore, instead of replacing the risk measures introduced in the
previous section, the SUDA scores and DIS-SUDA approach should be used
as a complementary method. As mentioned earlier, DIS-SUDA is
particularly useful in situations where taking an inventory of all
already available datasets and their variables is difficult.</p>
<p>ADD: why use SUDA: (Typically, after applying SDC methods, one would recalculate the
SUDA scores and compare them to the original values. One way to quickly
see the differences would be to rerun these visualizations and compare
them to the base for risk changes.)</p>
<p>ADD: reference to fig2</p>
<div class="figure align-center" id="id15">
<span id="fig2"></span><img alt="_images/image2.png" src="_images/image2.png" />
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Visualizations of DIS-SUDA scores</span></p>
</div>
</div>
</div>
<div class="section" id="risk-measures-for-continuous-variables">
<h2>Risk measures for continuous variables<a class="headerlink" href="#risk-measures-for-continuous-variables" title="Permalink to this headline">¶</a></h2>
<p>The principle of rareness or uniqueness of combinations of
quasi-identifiers (keys) is not useful for continuous variables, because
it is likely that all or many individuals will have unique keys.
Therefore, other approaches are exploited for measuring the disclosure
risk of continuous variables. These methods are based on uniqueness of
the values in the neighborhood of the original values. The uniqueness is
defined in different ways: in absolute terms (interval measure) or
relative terms (record linkage). Most measures are a posteriori
measures: they are evaluated after anonymization of the raw data,
compare the treated data with the raw data and evaluate for each
individual the distance between the values in the raw and the treated
data. This means that these methods are not useful for identifying
individuals at risk within the raw data, but rather show the
distance/difference between the dataset before and after anonymization
and can therefore be interpreted as evaluation of the anonymization
method. For that reason, they resemble the information loss measures
discussed in the Section <a class="reference external" href="utility.html">Measuring utility and information loss</a>.
Finally, risk measures for continuous
quasi-identifiers are also based on outlier detection. Outliers play an
important role in the re-identification of these records.</p>
<div class="section" id="record-linkage">
<h3>Record linkage<a class="headerlink" href="#record-linkage" title="Permalink to this headline">¶</a></h3>
<p>Record linkage is an a posteriori method that evaluates the number of
correct linkages when linking the perturbed values with the original
values. The linking algorithm is based on the distance between the
original and the perturbed values (i.e., distance-based record linkage).
The perturbed values are matched with the closest individual. It is
important to note that this method does not give information on the
initial risk, but is rather a measure to evaluate the perturbation
algorithm (i.e., it is designed to indicate the level of uncertainty
introduced into the variable by counting the number of records that
could be correctly matched).</p>
<p>Record linkage algorithms differ with respect to which distance measure
is used. When a variable has very different scaling than other
continuous variables in the dataset, rescaling the variables before
using record linkage is recommended. Very different scales may lead to
undesired results when measuring the multivariate distance between
records based on several continuous variables. Since these methods are
based on both the raw data and treated data, examples of their
applications require the introduction of SDC methods and are therefore
postponed to the case studies in the Section <a class="reference external" href="case_studies.html">Case Studies</a>.</p>
<p>Besides distance-based record linkage, another method for linking is
probabilistic record linkage (see <a class="reference internal" href="#doto03">DoTo03</a>). The
literature shows, however, that results from distance-based record
linkage are better than the results from probabilistic record linkage.
Individuals in the treated data that are linked to the correct
individuals in the raw data are considered at risk of disclosure.</p>
</div>
<div class="section" id="interval-measure">
<h3>Interval measure<a class="headerlink" href="#interval-measure" title="Permalink to this headline">¶</a></h3>
<p>Successful application of an SDC method should result in perturbed
values that are considered not too close to their initial values; if the
value is relatively close, re-identification may be relatively easy. In
the application of interval measures, intervals are created around each
perturbed value and then a determination is made as to whether the
original value of that perturbed observation is contained in this
interval. Values that are within the interval around the initial value
after perturbation are considered too close to the initial value and
hence unsafe and need more perturbation. Values that are outside of the
intervals are considered safe. The size of the intervals is based on the
standard deviation of the observations and a scaling parameter <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>ADD: size of interval</p>
<p>The size of the intervals is <span class="math notranslate nohighlight">\(k\)</span> times
the standard deviation. The larger <span class="math notranslate nohighlight">\(k\)</span>, the larger the intervals are, and hence
the larger the number of observations within the interval constructed
around their original values and the higher the risk measure.</p>
<p>For most values, this is a satisfactory approach. It is not a sufficient
measure for outliers, however. After perturbation, outliers will stay
outliers and are easily re-identifiable, even if they are sufficiently
far from their initial values. Therefore, outliers should be treated
with caution.</p>
</div>
<div class="section" id="outlier-detection">
<h3>Outlier detection<a class="headerlink" href="#outlier-detection" title="Permalink to this headline">¶</a></h3>
<p>Outliers are important for measuring re-identification risk in
continuous microdata. Continuous data are often skewed, especially
right-skewed. This means that there are a few outliers with very high
values relative to the other observations of the same variable. Examples
are income in household data, where only few individuals/households may
have very high incomes, or turnover data for firms that are much larger
than other firms in the sample are. In cases like these, even if these
values are perturbed, it may still be easy to identify these outliers,
since they will stay the largest values even after perturbation. (The
perturbation will have created uncertainty as to the exact value, but
because the value started out so much further away from other
observations, it may still be easy to link to the high-income individual
or very large firm.) Examples would be the only doctor in a
geographical area with a high income or one single large firm in one
industry type. Therefore, identifying outliers in continuous data is an
important step when identifying individuals at high risk. In practice,
identifying the values of a continuous variable that are larger than a
predetermined <span class="math notranslate nohighlight">\(p\%\)</span>-percentile might help identify outliers, and
thus units at greater risk of identification. The value of <span class="math notranslate nohighlight">\(p\)</span>
depends on the skewness of the data.</p>
<p>A second approach for outlier detection is a posteriori measure
comparing the treated and raw data. An interval is constructed around
the perturbed values as described in the previous section. If the
original values fall into the interval around the perturbed values, the
perturbed values are considered unsafe since they are too close to the
original values. There are different ways to construct such intervals,
such as rank-based intervals and standard deviation-based intervals.
<a class="reference internal" href="#teme08">TeMe08</a> propose a robust alternative for these
intervals. They construct the intervals based on the squared Robust
Mahalanobis Distance (RMD) of the individual values. The intervals are
scaled by the RMD such that outliers obtain larger intervals and hence
need to have a larger perturbation in order to be considered safe than
values that are not outliers. This method is illustrated in the Section
<a class="reference external" href="case_studies.html">Case Studies</a>.</p>
</div>
</div>
<div class="section" id="global-risk">
<h2>Global risk<a class="headerlink" href="#global-risk" title="Permalink to this headline">¶</a></h2>
<p>To construct one aggregate risk measure at the global level for the
complete dataset, we can aggregate the measures for risk at the
individual level in several ways. Global risk measures should be used
with caution: behind an acceptable global risk can hide some very
high-risk records that are compensated by many low risk records.</p>
<div class="section" id="mean-of-individual-risk-measures">
<h3>Mean of individual risk measures<a class="headerlink" href="#mean-of-individual-risk-measures" title="Permalink to this headline">¶</a></h3>
<p>A straightforward way of aggregating the individual risk measures is
taking the mean of all individuals in the sample, which is equal to
summing over all keys in the sample if multiplied by the sample
frequencies of these keys and dividing by the sample size <span class="math notranslate nohighlight">\(n\)</span>:</p>
<div class="math notranslate nohighlight">
\[R_{1} = \frac{1}{n}\sum_{i}^{}r_{k} = \frac{1}{n}\sum_{k}^{}{f_{k}r}_{k}\]</div>
<p><span class="math notranslate nohighlight">\(r_{k}\)</span> is the individual risk of key <span class="math notranslate nohighlight">\(k\)</span> that the
<span class="math notranslate nohighlight">\(i\)</span><sup>th</sup> individual shares (see the Section
<a class="reference internal" href="#categorical-key-variables-and-frequency-counts">Categorical key variables and frequency counts</a>).</p>
<p>The global risk in the example data in <a class="reference internal" href="#tab41"><span class="std std-numref">Table 1</span></a> is 0.01582, which is
the expected proportion of all individuals in the sample that could be
re-identified by an intruder. Another way of expressing the global risk
is the number of expected re-identifications, <span class="math notranslate nohighlight">\(n*R_{1}\)</span>, which is
in the example 10 * 0.01582.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This global risk measure should be used with
caution. The average risk can be relatively low, but a few individuals
could have a very high probability of re-identification.</p>
</div>
<p>An easy way to check for this is to look at the distribution of the individual risk
values or the number of individuals with risk values above a certain
threshold, as shown in the next section.</p>
</div>
<div class="section" id="count-of-individuals-with-risks-larger-than-a-certain-threshold">
<h3>Count of individuals with risks larger than a certain threshold<a class="headerlink" href="#count-of-individuals-with-risks-larger-than-a-certain-threshold" title="Permalink to this headline">¶</a></h3>
<p>All individuals belonging to the same key have the same individual risk,
<span class="math notranslate nohighlight">\(r_{k}\)</span>. Another way of expressing the total risk in the sample is
the total number of observations that exceed a certain threshold of
individual risk. Setting the threshold can be absolute (e.g., all those
individuals who have a disclosure risk higher than 0.05 or 5%) or
relative (e.g., all those individuals with risks higher than the upper
quartile of individual risk). In the example, no individual has
a higher disclosure risk than 0.05.</p>
<p>These calculations can then be used to treat data for individuals whose
risk values are above a predetermined threshold. For example, one could
suppress values of certain key variables for those individuals with
risk above a specified threshold. This is explained further in the Section
<a class="reference external" href="anon_methods.html#Localsuppression">Local suppression</a> .</p>
</div>
</div>
<div class="section" id="household-risk">
<h2>Household risk<a class="headerlink" href="#household-risk" title="Permalink to this headline">¶</a></h2>
<p>In many social surveys, the data have a hierarchical structure where an
individual belongs to a higher-level entity (see the Section
<a class="reference internal" href="#levels-of-risk">Levels of risk</a>). Typical
examples are households in social surveys or pupils in schools.
Re-identification of one household member can lead to re-identification
of the other household members, too. It is therefore easy to see that if
we take the household structure into account, the re-identification risk
is the risk that at least one of the household members is re-identified.</p>
<div class="math notranslate nohighlight">
\[r^{h} = P(A_{1} \cup A_{2} \cup … \cup A_{J}) = 1 - \prod_{j = 1}^{J}{1 - P(A_{j})},\]</div>
<p>where <span class="math notranslate nohighlight">\(A_{j}\)</span> is the event that the <span class="math notranslate nohighlight">\(j\)</span><sup>th</sup> member of
the household is re-identified and <span class="math notranslate nohighlight">\(P\left( A_{j} \right) = r_{k}\)</span>
is the individual disclosure risk of the <span class="math notranslate nohighlight">\(j\)</span><sup>th</sup> member.
For example, if a household member has three members with individual
disclosure risks based on their respective keys 0.02, 0.03 and 0.03,
respectively, the household risk is</p>
<div class="math notranslate nohighlight">
\[1 - (1 - 0.02)(1 - 0.03)(1 - 0.03)) = 0.078\]</div>
<p>The hierarchical or household risk cannot be lower than the individual
risk, and the household risk is always the same for all household
members. The household risk should be used in cases where the data
contain a hierarchical structure, i.e., where a household structure is
present in the data.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The size of a household is an important identifier itself,
especially for large households. Suppression of the actual size variable
(e.g., number of household members), however, does not suffice to remove
this information from the dataset, as a simple count of the household
members for a particular household will allow reconstructing this
variable as long as a household ID is in the data, which allows
assigning individuals to households. We flag this for the reader’s
attention as it is important. Further discussion on approaches to the
SDC process that take into account the household structure where it
exists can be found in the Section
<a class="reference external" href="anon_methods.html#Anonymizationofthequasi-identifierhouseholdsize">Anonymization of the quasi-identifier household size</a></p>
</div>
<div class="admonition-recommended-reading-material-on-risk-measurement admonition">
<p class="first admonition-title">Recommended Reading Material on Risk Measurement</p>
<p>Elliot, Mark J, Anna Manning, Ken Mayes, John Gurd, and Michael Bane.
2005. “SUDA: A Program for Detecting Special Uniques.” <em>Joint
UNECE/Eurostat Work Session on Statistical Data Confidentiality</em>.
Geneva.</p>
<p>Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing,
Eric Schulte Nordholt, Keith Spicer, and Peter Paul de Wolf. 2012.
<em>Statistical Disclosure Control.</em> Chichester: John Wiley &amp; Sons Ltd.
doi:10.1002/9781118348239.</p>
<p>Lambert, Diane. 1993.”Measures of Disclosure Risk and Harm.” <em>Journal of
Official Statistics</em> 9(2) : 313-331.</p>
<p>Machanavajjhala, Ashwin, Daniel Kifer, Johannes Gehrke, and
Muthuramakrishnan Venkitasubramaniam. 2007. “L-diversity: Privacy Beyond
K-anonymity.” <em>ACM Trans. Knowl. Discov. Data</em> 1 (Article 3)
(1556-4681). doi:10.1145/1217299.1217302.
https://ptolemy.berkeley.edu/projects/truststc/pubs/465/L%20Diversity%20Privacy.pdf. Accessed
July 6, 2018.</p>
<p class="last">Templ, Matthias, Bernhard Meindl, Alexander Kowarik, and Shuang Chen.
2014. “Introduction to Statistical Disclosure Control (SDC).”
<a class="reference external" href="http://www.ihsn.org/home/sites/default/files/resources/ihsn-working-paper-007-Oct27.pdf">http://www.ihsn.org/home/sites/default/files/resources/ihsn-working-paper-007-Oct27.pdf</a><em>.</em>
August 1. Accessed July 6, 2018.</p>
</div>
<table class="docutils footnote" frame="void" id="foot21" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Recoding a continuous variable is sometimes useful in cases where the
data contains only a few continuous variables. We will see in the Section
<a class="reference internal" href="#individual-risk">Individual risk</a> that many methods used for risk calculation depend on whether the
variables are categorical. We will also see that it is easier for the
measurement of risk if the data contains only categorical or only
continuous variables.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot22" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>This is discussed in greater detail in the following sections. In
cases where the number of possible values is large, recoding the
variable, or parts of the set it takes values on, to obtain fewer
distinct values is recommended.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot23" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[3]</a></td><td>Besides variables collected at the higher hierarchical level, also
variables collected at the lower level but with no (or little)
variation within the groups formed by the hierarchical structure
should be treated as higher level variables. An example could be
mother tongue, where most households are monolingual, but the
variable is collected at the individual level.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot24" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[4]</a></td><td>Religion, for example, can be shared by all household members in
some countries, whereas in other countries this variable is measured
at the individual level and mixed-religion households exist.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot26" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[5]</a></td><td>The assumptions for this risk measure are strict and the risk is
estimated in many cases higher than the actual risk. Among other
assumptions, it is assumed that all individuals in the sample are
also included in the external file used by the intruder to match
against. If this is not the case, the risk is much lower; if the
individual in the released file is not contained in the external
file, the probability of a correct match is zero. Other assumptions
are that the files contain no errors and that both sets of data were
collected simultaneously, i.e. they contain the same information.
These assumptions will often not hold generally, but are necessary
for computation of a measure. An example of a violation of the last
assumptions is could occur if datasets are collected at different
points in time and records have changed. This could happen when
people move or change jobs and makes correct matching impossible. The
assumptions assume a worst-case scenario.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot30" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[6]</td><td>Besides distinct <span class="math notranslate nohighlight">\(l\)</span>-diversity, there are other
<span class="math notranslate nohighlight">\(l\)</span>-diversity methods: entropy and recursive. Distinct
<span class="math notranslate nohighlight">\(l\)</span>-diversity is most commonly used.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot31" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[7]</a></td><td>There are more combinations of quasi-identifiers that make record 5
unique (e.g., {‘Rural’, ‘Female’} and {‘Female’, ‘Secondary
Complete’, ‘Unemployed’}. These combinations, however, are not
considered MSUs because they do not fulfill the <strong>minimal</strong> subset
requirement. They contain subsets that are MSUs.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot32" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[8]</a></td><td>OECD, <a class="reference external" href="http://stats.oecd.org/glossary">http://stats.oecd.org/glossary</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="foot33" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id8">[9]</a></td><td>The third record has one MSU, {‘Primary incomplete’}; the seventh
record has one MSU, {‘Primary complete’}; and the eighth record has
three MSUs, {‘Urban, Unemployed’}, {‘Male, Unemployed’} and
{‘Post-secondary’}.</td></tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="doto03" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[DoTo03]</td><td>Domingo-Ferrer, J., &amp; Torra, V. (2003).
<strong>Disclosure Risk Assesment in Statistical Microdata Protection via Advanced Record Linkage.</strong>
Statistics and Computing 13 (4), 343-354</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="elma03" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[ElMa03]</td><td>Elliot , M. J., &amp; Manning, A. M. (2003).
<strong>Using DIS to Modify the Classification of Special Uniques.</strong>
Invited Paper. Joint ECE/Eurostat Work Session on Statistical Data Confidentiality. Luxemboug 2-9 April 2003.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="elmf02" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[ElMF02]</td><td>Elliot, M. J., Manning, A. M., &amp; Ford, R. W. (2002).
<strong>A Computational Algorithm for Handling the Special Uniques Problem.</strong>
International Journal of Uncertainty, Fuzziness and Knowledge Based System , 10 (5), 493-509.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="elmp10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[ELMP10]</td><td>Elliot, M. J., Lomax, S., Mackey, E. &amp; Purdam, K. (2010)
<strong>Data Environment Analysismand the Key Variable Mapping System.</strong>
In Privacy in Databases, PSD 2010 (ed. Domingo-Ferrer, J. &amp; Magkos, E.), vol. 6344 of Lecture Notes in Computer Science, pp. 138-145. Berlin/Heidelberg: Springer</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="elsd98" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[ElSD98]</td><td>Elliot, M.J., Skinner, C.J. &amp; Dale, A. (1998)
<strong>Special Uniques, Random Uniques, and Sticky Populations: Some Counterintuitive Effects of Geographical Detail on Disclosure Risk</strong>
Reasearch in Official Statistics 1(2), pp. 53-67</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="emmg05" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[EMMG05]</td><td>Elliot, M. J., Manning, A., Mayes, K., Gurd, J., &amp; Bane, M. (2005).
<strong>SUDA: A Program for Detecting Special Uniques.</strong>
Joint UNECE/Eurostat Work Session on Statistical Data Confidentiality. Geneva.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="hdfg12" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[HDFG12]</td><td>Hundepool, A., Domingo-Ferrer, J., Franconi, L., Giessing, S., Nordholt, E. S., Spicer, K., et al. (2012).
<strong>Statistical Disclosure Control.</strong>
Chichester, UK: John Wiley &amp; Sons Ltd.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="lamb93" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Lamb93]</td><td>Lambert, D. (1993).
<strong>Measures of Disclosure Risk and Harm.</strong>
Journal of Official Statistics , 9 (2), 313-331.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="mahk08" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[MaHK08]</td><td>Manning, A. M., Haglin, D. J., &amp; Keane, J. A. (2008).
<strong>A Recursive Search Algorithm for Statistical Disclosure Assessment.</strong>
Data Mining and Knowledge Discovery , 16 (2), 165-196.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="mkgv07" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[MKGV07]</td><td>Machanavajjhala, A., Kifer, D., Gehrke, J., &amp; Venkitasubramaniam, M. (2007).
<strong>L-diversity: Privacy Beyond K-anonymity.</strong>
ACM Trans. Knowl. Discov. Data , 1 (Article 3) (1556-4681).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="teme08" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[TeMe08]</td><td>Templ, M. &amp; Meindl, B. (2008)
<strong>Robust Statistics Meets SDC: New Disclosure Risk Measures for Continuous Microdata Masking.</strong>
In Privacy in Statistical Databases, PSD 2008 (eds. Domingo-Ferrer J. and Saygin Y.), vol. 5262 of Lecture Notes in Computer Science, pp. 177-189. Berlin/Heidelberg: Springer.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="temk14" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[TeMK14]</td><td>Templ, M., Meindl, B., &amp; Kowarik, A. (2014, August).
<strong>Tutorial for SDCMicroGUI.</strong>
Retrieved from International Household Survey Network (IHSN): <a class="reference external" href="http://www.ihsn.org/home/software/disclosure-control-toolbox">http://www.ihsn.org/home/software/disclosure-control-toolbox</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tmkc14" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[TMKC14]</td><td>Templ, M., Meindl, B., Kowarik, A., &amp; Chen, S. (2014, August 1).
<strong>Introduction to Statistical Disclosure Control (SDC).</strong>
Retrieved November 13, 2014, from <a class="reference external" href="http://www.ihsn.org/home/software/disclosure-control-toolbox">http://www.ihsn.org/home/software/disclosure-control-toolbox</a>.</td></tr>
</tbody>
</table>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="anon_methods.html" class="btn btn-neutral float-right" title="Anonymization Methods" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="release_types.html" class="btn btn-neutral" title="Release Types" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Thijs Benschop, Cathrine Machingauta, Matthew Welch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>